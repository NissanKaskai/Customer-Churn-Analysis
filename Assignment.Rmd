---
output:
  #word_document: default
  #pdf_document: default
  html_document: default
---

**loading libraries**

```{r message=FALSE}
library(corrplot)
library(leaps)
library(hrbrthemes)
library(tidyverse)
library(caret)
library(pROC)
library(nnet)
library(rpart)
library(rpart.plot)
```

**Importing the CSV files**

```{r}
in13 <- read.csv('in13.csv', row.names = 1)
an13 <- read.csv('an13.csv', row.names = 1)
dati1 <- read.csv('dati1.csv', row.names = 1)
```

#CLV

# First part: COSTS
```{r}
in13_forCLV= in13%>%
  group_by(CodCliente) %>%
  summarize(sum=sum(importo))%>%
  arrange(desc(sum))

in13_forCLV
mean_value= sum(in13_forCLV$sum)/nrow(in13_forCLV)
mean_value
```

30.66 euros is the mean amount of euro that each customer would spend if he/she wouldn't have a card.
Because the card-association pays each museum 50% of the real price for each visit, they pay around 15 euros annually for each customer.

# Second part: REVENUES
```{r}
an13_forCLV= an13%>%
  select(codcliente,importo)%>%
  summarize(sum=sum(importo)/nrow(an13))

an13_forCLV
```
So the card society gains from each customer: 35-15= 20 euros (on average)

20 euros is the CV, but we need the CLV

```{r}
dati1_forCLV= dati1%>%
  select(codcliente,eta13)%>%
  summarize(mean_age=mean(eta13))

dati1_forCLV
```

The mean age is 52 years. Considering a normal lifetime of about 86 years, we obtain the CLV:
CLV=(86-52)x20 = 34x20 = 760 euros



# Data cleaning

**Looking for NA values**

```{r}
sum(is.na(in13))
sum(is.na(an13))
sum(is.na(dati1))

# As we can observe, the datasets 'an13' and 'dati1' 
# contains many missing values, while '1n13' has 0 NA.
```

**Now let's analyze each csv singularly:**

##   in13:

```{r}
in13$prov_museo[in13$museo == "CENTRO FAUNISTICO UOMINI E LUPI"] <- "CN"
in13$com_museo[in13$museo == "CENTRO FAUNISTICO UOMINI E LUPI"] <- "ENTRACQUE"
in13$prov_museo[in13$museo == "MOSTRA BORN SOMEWHERE"] <- "TO"
in13$com_museo[in13$museo == "MOSTRA BORN SOMEWHERE"] <- "TORINO"
```

##   an13:

```{r}
sapply(an13, function(x) sum(is.na(x)))

# The number of NAs in the variable "professione" is equal to the observations, 
# that means that all the "professione" observations are NAs, so we remove them.

# As we can see, all the remaining Nas are from the variable sex, other variables
# have data different from NA.
```
```{r}
an13$professione <- NULL
```


### Pulizia cap

```{r}
# an13 %>% filter(cap=='XXXXX') #-->2899


#First: create cap for Turin --> 2328
generate_cap_for_turin <- function(comune, cap) {
  if (comune == 'TORINO' && cap == 'XXXXX') {
    return('10100')
  }
  return(cap)
}

an13$cap <- mapply(generate_cap_for_turin, an13$comune, an13$cap)


#second: delete rows with dato mancante and XXXXX --> 181
an13 <- subset(an13, !(comune == 'DATO MANCANTE' & cap == 'XXXXX'))

#third: deleting remaining rows with XXXXX --> 181
an13 <- subset(an13, !( cap == 'XXXXX'))

#see results
# an13 %>% filter(cap=='XXXXX')
```

### Pulizia comune

```{r}
# an13 %>% filter(comune=='DATO MANCANTE') #-->1238
cap=read_csv('Cap.csv', show_col_types = FALSE)
# cap
matching_indices <- match(an13$cap, cap$CAP)

# Identify the rows in 'an13' with missing 'Comune' values ('DATO MANCANTE')
missing_comune_rows <- an13$comune == "DATO MANCANTE"

# Update the missing 'Comune' values in 'an13' using the 'cap' dataset
an13$comune[missing_comune_rows] <- cap$Comune[matching_indices[missing_comune_rows]]
# an13 %>% filter(comune=='DATO MANCANTE')
```

```{r}
an13 <- an13[an13$data_nascita != "1-01", ]
an13 <- an13[an13$data_nascita != "9-02", ]
an13$data_nascita <- as.integer(an13$data_nascita)
an13 <- an13[an13$data_nascita <2014, ]
```


```{r}
sapply(an13, function(x) sum(is.na(x)))

# As we can see, only two observations in "data_nascita" are now NA, that means
# that two observations were incorrect
```


##   dati1:

```{r}
sapply(dati1, function(x) sum(is.na(x)))

# The number of NAs in the variable "sesso" is pretty much the same
# in the an13 dataset, at this point we can assume that most of the
# missing values are the same for both datasets and we can remove them
```

```{r}
# Removing obs with wrong province
dati1 <- dati1[dati1$codcliente != 215415, ]
dati1 <- dati1[dati1$codcliente != 15090, ]
dati1 <- dati1[dati1$codcliente != 7926, ]
```


```{r}
sum(is.na(dati1$nvisite0512))
sum(is.na(dati1$nmusei0512))
# The number of Nas are the same in the two variables, so we can assume that
# having no data correspond to not having visited any museum. We then change
# the Nas to 0
```

```{r}
dati1["nvisite0512"][is.na(dati1["nvisite0512"])] <- 0
dati1["nmusei0512"][is.na(dati1["nmusei0512"])] <- 0
```

```{r}
sum(dati1$si2014 == 0)
sum(is.na(dati1$abb14))
# The number of Nas is pretty much the same, so we can assume that customers
# that have churned from the contract have been recorded with NA in the 
# "abb14" variable, so we can change their value to 0
```

```{r}
 dati1 <- dati1 %>%
   mutate(abb14 = ifelse(si2014 == 0, 0, abb14))
```

```{r}
sapply(dati1, function(x) sum(is.na(x)))

# Chiedere nvisite0512 e nmusei0512,
# cambiare provincia con comune in an13 relativo al codicecliente, se cambio cap = 0
# ultimo ingresso da vedere
```

```{r}
# dati1["ultimo_ing.x"][is.na(dati1["ultimo_ing.x"])] <- -Inf
```

```{r}
dati1$churn <- ifelse(dati1$si2014 == 0, 1, 0)
# dati1$churn <- as.factor(dati1$churn)
# dati1 <- dati1[, -which(names(dati1) == "si2014")]
```


## Removing NA

```{r}
an13 <- na.omit(an13)
dati1 <- na.omit(dati1)
sum(is.na(an13))
sum(is.na(dati1))
```


```{r}
minus.t <- dati1[ , ! names(dati1) %in% c("codcliente", "si2013", "ultimo_ing.x", "abb13", "abb14", "prov", "sesso", "si2014")]
M = cor(minus.t)
corrplot(M, method='square', type = 'lower', number.cex = 0.9, tl.cex = 0.7, tl.col = 'black')
```

```{r}
in13$museo=as.factor(in13$museo)
in13$prov_museo=as.factor(in13$prov_museo)
in13$com_museo=as.factor(in13$com_museo)
in13$datai <- as.Date(in13$datai, "%d/%m/%Y")
in13$orai <- str_sub(in13$orai, end = -4)
in13$orai <- as.integer(in13$orai)
```

```{r}
an13$data_inizio <- str_sub(an13$data_inizio, end = -7) # remove hours and minutes
an13$data_inizio <- as.Date(an13$data_inizio, "%d/%m/%Y")
an13$sesso <- as.factor(an13$sesso)
an13$sconto <- as.factor(an13$sconto)
an13$riduzione <- as.factor(an13$riduzione)
an13$tipo_pag <- as.factor(an13$tipo_pag)
an13$agenzia <- as.factor(an13$agenzia)
an13$agenzia_tipo <- as.factor(an13$agenzia_tipo)
an13$comune <- as.factor(an13$comune)
an13$cap <- as.factor(an13$cap)
an13$nuovo_abb <- as.factor(an13$nuovo_abb)
```

```{r}
dati1$churn <- as.factor(dati1$churn)
dati1$si2013 <- as.factor(dati1$si2013)
dati1$si2014 <- as.factor(dati1$si2014)
dati1$sesso <- as.factor(dati1$sesso)
dati1$cambiocap0512 <- as.factor(dati1$cambiocap0512)
dati1$prov <- as.factor(dati1$prov)
dati1$ultimo_ing.x <- sub( '(?<=.{6})', '20', dati1$ultimo_ing.x, perl=TRUE)
dati1$abb13 <- sub( '(?<=.{6})', '20', dati1$abb13, perl=TRUE)
dati1$abb14 <- sub( '(?<=.{6})', '20', dati1$abb14, perl=TRUE)
dati1$ultimo_ing.x <- as.Date(dati1$ultimo_ing.x, "%d/%m/%Y")
dati1$abb13 <- as.Date(dati1$abb13, "%d/%m/%Y")
#dati1$abb14 <- as.Date(dati1$abb14, "%d/%m/%Y") --> resta character ma non lo includiamo nella regressione
sum(is.na(dati1))
```

# Descriptive Analysis


## dati1

```{r}
dati1$agegroup <- cut(dati1$eta13, 
                         breaks = c(-Inf, 18, 30, 45, 60, Inf),
                         labels = c("Below 18","18-29",
                                    "30-44","45-59", "60+"),
                         right = FALSE)
```


## in13

```{r}

#levels(in13$museo)
in13_plot= in13 %>% 
  group_by(museo) %>%
  summarise(mean_importo=mean(importo))%>%
  arrange((mean_importo))
```


## an13

```{r}
ggplot(an13)+
  geom_bar(aes(x=tipo_pag, fill=sesso)) 
  #theme_ipsum_rc(grid="Y")
```


```{r}
an13$comune =as.character(an13$comune)
an13$comune<- iconv(an13$comune, from = "latin1", to = "UTF-8")
an13$comune =as.factor(an13$comune)
#levels(an13$comune)
```



```{r}
an13$agenzia =as.character(an13$agenzia)
an13$agenzia<- iconv(an13$agenzia, from = "latin1", to = "UTF-8")
an13$agenzia =as.factor(an13$agenzia)
#levels(an13$agenzia)
```


```{r}
an13$riduzione <- as.character(an13$riduzione)

an13$riduzione <- ifelse(an13$riduzione == "OFFERTA CONVENZIONE 28\x80", "OFFERTA CONVENZIONE 28€", an13$riduzione)
an13$riduzione <- ifelse(an13$riduzione == "OFFERTA CONVENZIONE 33\x80", "OFFERTA CONVENZIONE 33€", an13$riduzione)
an13$riduzione <- ifelse(an13$riduzione == "OFFERTA SU QUANTITATIVO 30\x80", "OFFERTA SU QUANTITATIVO 30€", an13$riduzione)
an13$riduzione <- ifelse(an13$riduzione == "OFFERTA SU QUANTITATIVO 44\x80", "OFFERTA SU QUANTITATIVO 44€", an13$riduzione)
an13$riduzione <- ifelse(an13$riduzione == "PASS 60 e VOUCHER OFFERTA 30 \x80 ", "PASS 60 e VOUCHER OFFERTA 30€", an13$riduzione)

an13$riduzione <- as.factor(an13$riduzione)
```


```{r fig.dim=c(12,8), dpi=200}
ggplot(an13)+
  geom_bar(mapping=(aes(x=data_nascita, fill=riduzione))) 
  #theme_ipsum_rc(grid="Y")
```


```{r fig.dim=c(6,4), dpi=200}
ggplot(data = dati1, aes(x = agegroup)) +
  geom_bar(show.legend = FALSE, fill="#1380A1") +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust =-0.7) +
  expand_limits(y = 25000) +
  #theme_ipsum_rc(grid="Y") +
  scale_color_ft()
```

The above bar chart shows the overall age of customers. It is observed that the number of customers is the highest with an amount of 32,237 at age ranged 60+ which is the older crowd. 
From age range of 18-29 onwards the frequency of customers increases steadily as the age increase until age ABOVE 60 where a significantly higher frequency of customers was observed. Customers aged below 18 is the lowest at 2,055, this is probably because the company requires the customers to be at least 18 years old to register as a member. Hence, it explains the low number of customers in this range of age.

```{r fig.dim=c(6,4), dpi=200}
ggplot(dati1, aes(x = churn, fill=churn)) +
  geom_bar(show.legend = FALSE) +
  labs(title = "Population of Churners and Non-Churners", 
       x = "Churners", 
       y = "Count") +
  geom_text(stat = "count", aes(label = after_stat(count)), vjust =-0.7) +
  expand_limits(y = 45000) +
  scale_fill_manual(values = c("#1380A1", "#FAAB18")) 
  #theme_ipsum_rc(grid="Y")
```

Next, shows the population of churners and non-churners. 0 indicates that they are churners while 1 indicates that they are not churners.

```{r}
dati1$frequency13 <- cut(dati1$nvisit13, 
                         breaks = c(-Inf, 2, 5, 10, 20, Inf),
                         labels = c("0-1", "2-5", "5-9","10-19", "20+"),
                         right = FALSE)
```

```{r fig.dim=c(6,4), dpi=200}
ggplot(dati1, aes(x = frequency13, fill = churn)) +
  geom_bar() +
  scale_fill_manual(values = c("#1380A1", "#FAAB18")) 
  #theme_ipsum_rc(grid="Y")
```

When comparing Churner vs SpendFrequencyRange (see Figure 4), it is noticeable that most of the churners (yes) SpendFrequencyRange of 1, 2, 3, and 4-10 which means that they have only spent less than 10 times. Looking at SpendFrequencyRange of 1, it is almost a half-half distribution where there is a close number of churners and 
non-churners. This means that the members under the ‘no’ category could be new members while the members in the ‘yes’ category never continued using the card after once.

```{r fig.dim=c(6,4), dpi=200}
#sum(is.na(dati1))
ggplot(dati1) +
  aes(x = frequency13, fill = sesso) +
  geom_bar(position = "dodge") +
  scale_fill_manual(values = c("#FFDAC1", "#FFB7B2")) 
  #theme_ipsum_rc(grid="Y")
```

Above shows the spend frequency range of customers against gender. No matter the age range, females always has higher spend frequency range compared to males.

# Variable Selection

## Best Subset Selection

```{r}
model.null=glm(churn ~ 1, data = dati1, family = 'binomial')
model.full <- glm(churn ~ nvisit13+nmus13+nabb0512+nvisite0512+nmusei0512+sesso+eta13+prezzo13+cambiocap0512+prov, data = dati1, family = 'binomial')

# Perform both forward selection and backward elimination
step(model.null, scope = list(upper=model.full),direction="both",trace=1,k=2)

```

Here we computed Stepwise Selection, with both Forward and Backward direction, and used AIC as decisional criterion.
From this analysis we discovered that we have one less significant variable, 'prov', and we removed it. 
We had also previously eliminated variables: 'si2013', 'si2014', 'abb14', 'agegroup' and 'frequency13'. The reason is the following: 'si2013' contains only one level, 'si2014' is the one we built the variable 'churn' on, 'abb14' has been excluded because we will treat this particular character variable separately, moreover we don't think that the renewal day is significant to predict the 'churn' variable. Finally, 'agegroup' and 'frequency13' has been excluded because they represent the same information contained in 'eta13' and 'nvisit13'.

The remaining variables are: 'nvisit13', 'nabb0512', 'nmus13', 'nvisite0512', 'nmusei0512', 'sesso', 'eta13', 'prezzo13', 'cambiocap0512'.

# Prediction

## Data Partition 80/20 Split

```{r}
set.seed(1)
trainIndex <- createDataPartition(dati1$churn, p=.8, list=FALSE)
train_data <- dati1[trainIndex,]
test_data <- dati1[-trainIndex,]
```


## Logistic Regression

```{r}
library(ROCR)

# Train a logistic regression model
model<- glm(churn ~ nvisit13+nmus13+nabb0512+nvisite0512+nmusei0512+sesso+eta13+prezzo13+cambiocap0512, data = dati1, family = 'binomial')

# Make predictions on the test set
predictions <- predict(model, newdata = test_data, type = "response")

# Calculate the confusion matrix
confusion_matrix <- table(test_data$churn, predictions > 0.5)
confusion_matrix

# Calculate accuracy and other performance metrics
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
precision <- confusion_matrix[2, 2] / sum(confusion_matrix[, 2])
recall <- confusion_matrix[2, 2] / sum(confusion_matrix[2, ])
f1_score <- 2 * (precision * recall) / (precision + recall)

# Calculate ROC-AUC
roc <- prediction(predictions, test_data$churn)
auc <- as.numeric(performance(roc, "auc")@y.values)

# Print the evaluation metrics and ROC-AUC
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall:", recall, "\n")
cat("F1 Score:", f1_score, "\n")
cat("ROC-AUC:", auc, "\n")
```


```{r}
# Define your budget and cost per contact
budget <- 5000  # Your budget in euros
cost_per_phone_call <- 1  # 1 euro per phone call
cost_per_email <- 0.15  # 0.15 euros per email

# Define response rates based on past campaigns
response_rate_phone_call <- 0.35
response_rate_email <- 0.15

# Initialize variables to keep track of the best distribution and profit
best_profit <- 0
best_phone_call_budget <- 0
```

```{r}
for (phone_call_budget in seq(0, budget, by = 1)) {
  email_budget <- budget - phone_call_budget
  
  # Calculate the number of phone calls and emails based on budget allocation
  num_phone_calls <- min(phone_call_budget / cost_per_phone_call, length(predictions))
  num_emails <- min(email_budget / cost_per_email, length(predictions))
  
  # Sort predictions in descending order
  sorted_predictions <- sort(predictions, decreasing = TRUE)
  
  # Calculate response rates based on the allocated budget and model predictions
  if (num_phone_calls > 0) {
    response_rate_phone_call <- sum(sorted_predictions[1:num_phone_calls]) / num_phone_calls
  } else {
    response_rate_phone_call <- 0
  }
  if (num_emails > 0) {
    response_rate_email <- sum(sorted_predictions[(num_phone_calls + 1):(num_phone_calls + num_emails)]) / num_emails
  } else {
    response_rate_email <- 0
  }
  
  # Calculate the expected profit for the current allocation
  profit_phone_call <- (response_rate_phone_call * phone_call_budget) - (cost_per_phone_call * num_phone_calls)
  profit_email <- (response_rate_email * email_budget) - (cost_per_email * num_emails)
  total_profit <- profit_phone_call + profit_email
  
  # Check if the current allocation results in higher profit
  if (!is.na(total_profit) && total_profit > best_profit) {
    best_profit <- total_profit
    best_phone_call_budget <- phone_call_budget
  }
}

# Print the best allocation and profit
cat("Best Phone Call Budget:", best_phone_call_budget, "euros\n")
cat("Best Email Budget:", budget - best_phone_call_budget, "euros\n")
cat("Total Profit:", best_profit, "euros\n")
```


```{r}
# Iterate through different budget allocations
for (phone_call_budget in seq(0, budget, by = 1)) {
  email_budget <- budget - phone_call_budget
  
  # Calculate the number of phone calls and emails based on budget allocation
  num_phone_calls <- min(phone_call_budget / cost_per_phone_call, length(predictions))
  num_emails <- min(email_budget / cost_per_email, length(predictions))
  
  # Sort predictions in descending order
  sorted_predictions <- sort(predictions, decreasing = TRUE)
  
  # Calculate response rates based on the allocated budget and model predictions
  response_rate_phone_call <- sum(sorted_predictions[1:num_phone_calls]) / num_phone_calls
  response_rate_email <- sum(sorted_predictions[(num_phone_calls + 1):(num_phone_calls + num_emails)]) / num_emails
  
  # Calculate the expected profit for the current allocation
  profit_phone_call <- (response_rate_phone_call * phone_call_budget) - (cost_per_phone_call * num_phone_calls)
  profit_email <- (response_rate_email * email_budget) - (cost_per_email * num_emails)
  total_profit <- profit_phone_call + profit_email
  
  # Check if the current allocation results in higher profit
  if (total_profit > best_profit) {
    best_profit <- total_profit
    best_phone_call_budget <- phone_call_budget
  }
}

# Print the best allocation and profit
cat("Best Phone Call Budget:", best_phone_call_budget, "euros\n")
cat("Best Email Budget:", budget - best_phone_call_budget, "euros\n")
cat("Total Profit:", best_profit, "euros\n")


```


